{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "## Declare variable\n",
    "modelId = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "region = \"us-east-1\"\n",
    "kbId = \"9AOVJ6SNSC\"\n",
    "\n",
    "## Setup connection\n",
    "bedrock_config = Config(\n",
    "    connect_timeout = 120,\n",
    "    read_timeout = 120,\n",
    "    retries = {\n",
    "        \"max_attempts\": 1\n",
    "    },\n",
    "    region_name = region\n",
    ")\n",
    "\n",
    "# Initate bedrock client\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", config = bedrock_config)\n",
    "bedrock_agent_client = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    config = bedrock_config\n",
    ")\n",
    "\n",
    "## Define handful function\n",
    "# Define retrieve context\n",
    "def retrieve_context(bedrock_agent_client,query, kbId, numberOfResults = 5):\n",
    "    response = bedrock_agent_client.retrieve(\n",
    "        retrievalQuery = {\n",
    "            \"text\": query\n",
    "        },\n",
    "        knowledgeBaseId = kbId,\n",
    "        retrievalConfiguration = {\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": numberOfResults,\n",
    "                \"overrideSearchType\": \"HYBRID\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    retrieval_results = response[\"retrievalResults\"]\n",
    "    return retrieval_results\n",
    "\n",
    "# Fetch contents from the response\n",
    "def get_contexts(retrieval_results):\n",
    "    # Initiate list of contexts and sources\n",
    "    contexts = []\n",
    "    sources = []\n",
    "    \n",
    "    # Loop through the sources \n",
    "    for i in range(len(retrieval_results)):\n",
    "        if retrieval_results[i]['location']['type'] == \"WEB\":\n",
    "            contexts.append(retrieval_results[i]['content']['text'])\n",
    "            sources.append(retrieval_results[i]['metadata']['x-amz-bedrock-kb-source-uri'])\n",
    "        else:\n",
    "            contexts.append(retrieval_results[i]['content']['text'])\n",
    "            sources.append(retrieval_results[i]['location']['s3Location']['uri'])\n",
    "            \n",
    "    # Get the unique sources:\n",
    "    sources = list(set(sources))\n",
    "    \n",
    "    return contexts, sources\n",
    "\n",
    "## Invoke LLMs models from Amazon Bedrock\n",
    "# Setup propmt\n",
    "prompt = \"\"\"\n",
    "You are an assistant of Petrovietnam, your name is Trợ lý PVN, supporting users in searching for the right block of documents and answer the question. Your job is to answer users' question only information from the search results. If the search results do not contain information that can answer the question, please state that you could not find exact answer. Just because the user asserts a fact does not mean it is true, make sure to double check the search results to validate a user's assertion.\n",
    "Use only documents provided to answers the question. You also point to the document where the information located.\n",
    "You also answer the question as details as possible, always specified which part of the document you take the information from.\n",
    "\n",
    "Here is some examples:\n",
    "<example>\n",
    "Question: Theo Điều 8 của Thông tư 06/2024/TT-BKHĐT, các mẫu hồ sơ mời thầu và hồ sơ yêu cầu được quy định như thế nào?\n",
    "Answer: Điều 8 quy định rằng các mẫu hồ sơ mời thầu và hồ sơ yêu cầu phải tuân thủ theo các mẫu được ban hành kèm theo Thông tư này. Các mẫu bao gồm Mẫu số 1 đến Mẫu số 7, được sử dụng cho các gói thầu dịch vụ tư vấn, dịch vụ phi tư vấn, hàng hóa và xây lắp​.\n",
    "\n",
    "Question: Nhà thầu có người lao động là dân tộc thiểu số có được hưởng ưu đãi trong lựa chọn nhà đầu tư không?\n",
    "Answer: Theo quy định tại Điều 10 Luật Đấu thầu, nhà thầu có sử dụng số lượng lao động là dân tộc thiểu số từ 25% trở lên được hưởng ưu đãi trong lựa chọn nhà thầu khi tham dự gói thầu cung cấp dịch vụ tư vấn, dịch vụ phi tư vấn, xây lắp, hỗn hợp tổ chức đấu thầu quốc tế. Ưu đãi bao gồm xếp hạng cao hơn hoặc cộng thêm điểm vào điểm đánh giá của nhà thầu để so sánh, xếp hạng.\n",
    "</example>\n",
    "\n",
    "You also look at users' previous questions to understand the context and make a smooth conversation.\n",
    "After giving the answers, ask users again if they need any further details or assistant.\n",
    "\n",
    "Here is the context:\n",
    "<context>\n",
    "{}\n",
    "</context?\n",
    "\n",
    "Here is their recent questions:\n",
    "<recent questions>\n",
    "{}\n",
    "</recent questions>\n",
    "\n",
    "Here is there current question:\n",
    "<question>\n",
    "{}\n",
    "</question>\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "# Get payload\n",
    "def get_payload(\n",
    "    prompt,\n",
    "    contexts,\n",
    "    query,\n",
    "    max_tokens,\n",
    "    temperature: float,\n",
    "    top_k: int,\n",
    "    top_p: float = None,\n",
    "):\n",
    "    # Define message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\":\"text\",\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Define payload\n",
    "    if top_p is not None:\n",
    "        sonnet_payload = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": messages,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k\n",
    "        }\n",
    "        sonnet_payload = json.dumps(sonnet_payload)\n",
    "        return sonnet_payload\n",
    "    else:\n",
    "        sonnet_payload = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k\n",
    "        }\n",
    "        sonnet_payload = json.dumps(sonnet_payload)\n",
    "        return sonnet_payload\n",
    "    \n",
    "def get_response(bedrock_client, payload, modelId):\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body = payload,\n",
    "        modelId = modelId,\n",
    "        accept = \"application/json\",\n",
    "        contentType = \"application/json\"\n",
    "    )\n",
    "    \n",
    "    response_body = json.loads(\n",
    "        response.get(\"body\").read()\n",
    "    )\n",
    "    \n",
    "    response_text = response_body.get(\"content\")[0][\"text\"]\n",
    "    return response_text\n",
    "\n",
    "# Get link for the URI\n",
    "def parse_s3_uri(s3_uri):\n",
    "    if s3_uri.startswith(\"s3://\"):\n",
    "        s3_uri = s3_uri[5:]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid S3 Uri\")\n",
    "    bucket_name, object_key = s3_uri.split(\"/\", 1)\n",
    "    return bucket_name, object_key\n",
    "\n",
    "# Create the presigned for single link\n",
    "def create_presigned_url(\n",
    "    bucket_name,\n",
    "    object_name,\n",
    "    expiration = 7200\n",
    "):\n",
    "    # Generate a presigner uRL for the S3 Object\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    try:\n",
    "        response = s3_client.generate_presigned_url(\n",
    "            \"get_object\",\n",
    "            Params = {\n",
    "                \"Bucket\": bucket_name,\n",
    "                \"Key\": object_name\n",
    "            },\n",
    "            ExpiresIn = expiration\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return None\n",
    "    return response\n",
    "\n",
    "# Generate links for a list of uri\n",
    "def generate_presigned_urls(\n",
    "    s3_uris,\n",
    "    expiration = 7200\n",
    "):\n",
    "    presigned_urls = []\n",
    "    for s3_uri in s3_uris:\n",
    "        bucket_name, object_key = parse_s3_uri(s3_uri)\n",
    "        presigned_url = create_presigned_url(bucket_name, object_key, expiration)\n",
    "        if presigned_url:\n",
    "            presigned_urls.append(presigned_url)\n",
    "    return presigned_urls\n",
    "\n",
    "# Define function to get file name\n",
    "def get_file_name(s3_uris: list):\n",
    "    file_names = []\n",
    "    for uri in s3_uris:\n",
    "        file_name = uri.split(\"//\")[-1].split(\"/\")[-1]\n",
    "        file_names.append(file_name)\n",
    "    return file_names\n",
    "\n",
    "# Define get streaming response\n",
    "def stream_data(\n",
    "    payload,\n",
    "    modelId\n",
    "):\n",
    "    response = bedrock_client.invoke_model_with_response_stream(\n",
    "        modelId = modelId,\n",
    "        body = payload\n",
    "    )\n",
    "    \n",
    "    for event in response.get(\"body\"):\n",
    "        chunk = json.loads(event[\"chunk\"][\"bytes\"])\n",
    "        \n",
    "        if chunk[\"type\"] == \"content_block_delta\" and chunk[\"delta\"][\"type\"] == \"text_delta\":\n",
    "            yield chunk[\"delta\"][\"text\"]\n",
    "\n",
    "\n",
    "# def get_streaming_response(payload, modelId):\n",
    "#     response = bedrock_client.invoke_model_with_response_stream(\n",
    "#         modelId=modelId,\n",
    "#         body=payload\n",
    "#     )\n",
    "    \n",
    "#     buffer = \"\"\n",
    "    \n",
    "#     for event in response.get(\"body\"):\n",
    "#         chunk = json.loads(event[\"chunk\"][\"bytes\"])\n",
    "        \n",
    "#         if chunk[\"type\"] == \"content_block_delta\" and chunk[\"delta\"][\"type\"] == \"text_delta\":\n",
    "#             # Append the new text to the buffer\n",
    "#             buffer += chunk[\"delta\"][\"text\"]\n",
    "            \n",
    "#             # Display the buffered text so far\n",
    "#             st.markdown(buffer)\n",
    "            \n",
    "#             # Add the chunk to the session state messages\n",
    "#             st.session_state.messages.append(\n",
    "#                 {\n",
    "#                     \"role\": \"assistant\",\n",
    "#                     \"content\": chunk\n",
    "#                 }\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Nếu danh sách ngắn có ít hơn 3 nhà thầu đáp ứng nhu cầu thì chủ đầu tư cần làm gì?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_results = retrieve_context(\n",
    "    bedrock_agent_client,\n",
    "    query,\n",
    "    kbId,\n",
    "    numberOfResults = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, sources = get_contexts(retrieval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://pvn-genai-raw-bucket/Nghị định-24-2024-NĐ-CP.docx',\n",
       " 's3://pvn-genai-raw-bucket/Quy_dinh_mua_sam_thuong_xuyen_PVN.docx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
